{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet ML: Estimation du coût d'un bien immobilier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Itération 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des bibliothèques utiles et chargement du jeu Sberbank\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# read the data\n",
    "df = pd.read_csv('sberbank.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code ici\n",
    "#remplcer les valeurs null dans les colones non nummériques par la valeur la plus fréquente\n",
    "\n",
    "df_categoric = df.select_dtypes(exclude='number')\n",
    "categoric_cols = df_categoric.columns.values\n",
    "\n",
    "for col in categoric_cols:\n",
    "    missing = df[col].isnull()\n",
    "    num_missing = np.sum(missing)\n",
    "    \n",
    "    if num_missing > 0:  # only do the imputation for the columns that have missing values.\n",
    "        print(col)\n",
    "        top = df[col].describe()['top'] # impute with the most frequent value.\n",
    "        \n",
    "        df[col] = df[col].fillna(top)\n",
    "        \n",
    "\n",
    "\n",
    "#remplcer les valeurs null dans les colones nummériques par la valeur la mediane\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "\n",
    "numeric_cols = df_numeric.columns.values\n",
    "\n",
    "for col in numeric_cols:\n",
    "    missing = df[col].isnull()\n",
    "    num_missing = np.sum(missing)\n",
    "    \n",
    "    if num_missing > 0:  # only do the imputation for the columns that have missing values.\n",
    "        med = df[col].median()\n",
    "        df[col] = df[col].fillna(med)\n",
    "\n",
    "        df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des données aberrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrire la méthodologie adoptée pour faire le traitement\n",
    "#code ici\n",
    "#Utilisation de la règle interquartile pour trouver des valeurs aberrantes\n",
    "df.boxplot(column='price_doc')\n",
    "Q1=df.max_floor.quantile(0.25)\n",
    "Q3=df.max_floor.quantile(0.75)\n",
    "Q=df.max_floor.describe()\n",
    "IQR=Q3-Q1\n",
    "print(IQR)\n",
    "print(Q1)\n",
    "print(Q3)\n",
    "ind=df[(df['price_doc'] < Q1-1.5*IQR )].index\n",
    "ind2=df[(df['price_doc'] > Q3+1.5*IQR )].index\n",
    "#df3[ind,'max_floor']=Q1\n",
    "#| (df3['price_doc'] > Q3+1.5*IQR  )].index| (df3['price_doc'] > Q3+1.5*IQR  )].index\n",
    "print(df.shape)\n",
    "print(len(ind2))\n",
    "print(len(ind))\n",
    "df.loc[ind,'price_doc']=Q1\n",
    "df.loc[ind2,'price_doc']=Q3\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement du problème d'incohérence des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrire la méthodologie adoptée pour faire le traitement\n",
    "#code ici\n",
    "#supression des espaces blancs au debut\n",
    "df[\"sub_area\"] = df[\"sub_area\"].str.lstrip()\n",
    "df[\"sub_area\"]\n",
    "#supression des espaces blancs à la fin\n",
    "df[\"sub_area\"] = df[\"sub_area\"].str.rstrip()\n",
    "print(df[\"sub_area\"])\n",
    "#supression des espaces entre les mots\n",
    "\n",
    "df['sub_area'] = df['sub_area'].str.replace(' ','')\n",
    "print(df[\"sub_area\"])\n",
    "\n",
    "#formater les dates\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'],format='%Y-%m-%d')\n",
    "\n",
    "#supression des symboles monétaires\n",
    "money_chars = [\"$\",\"€\",\"¢\",\"£\",\"₿\"]\n",
    "for column in df.columns:\n",
    "    df[column]= df[column].replace('money_chars','')\n",
    "    \n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement du problème de redondances des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code ici\n",
    "##df2.drop('price_doc', axis=1).drop_duplicates()\n",
    "\n",
    "# drop rows with a lot of missing values.\n",
    "ind_missing = df[df['price_doc'] > 35].index\n",
    "df = df.drop(ind_missing, axis=0)\n",
    "print(df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code ici\n",
    "DFCat=df[categoric_cols]\n",
    "DFNum=df[numeric_cols]\n",
    "DFCat.head()\n",
    "print(DFCat.shape)\n",
    "DFCat.head()\n",
    "DFCat['culture_objects_top_25']=DFCat['culture_objects_top_25'].replace({\"no\":0,\n",
    " \"yes\":1})\n",
    "DFCat.replace({\"no\":0,\"yes\":1},inplace=True)\n",
    "from sklearn import preprocessing\n",
    "DFCat=df[categoric_cols]\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "DFCat['culture_objects_top_25']= label_encoder.fit_transform(DFCat['culture_objects_top_25'])\n",
    "\n",
    "\n",
    "df = df.drop(columns='product_type')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code ici\n",
    "from sklearn.model_selection import train_test_split\n",
    "Data2=df[numeric_cols]\n",
    "df_y=Data2[['price_doc']]\n",
    "df_x=Data2.drop(columns=['price_doc'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size = 0.2, random_state = 4 )\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train) \n",
    "xtrainnorm=scaler.transform(x_train)           \n",
    "xtestnorm=scaler.transform(x_test)           \n",
    "\n",
    "print(xtrainnorm.mean())\n",
    "print(xtrainnorm.std())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement et optimisation des paramètres d'un modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code ici\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kbins = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "ytrain_trans = kbins.fit_transform(y_train)\n",
    "ytest_trans = kbins.transform(y_test)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "model.fit(x_train, ytrain_trans)\n",
    "\n",
    "print(model.score(x_train, ytrain_trans)*100,'%')\n",
    "print(model.score(x_test, ytest_trans)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation d'un modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code ici\n",
    "# Decision tree Classfication\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,max_depth=5, min_samples_leaf=20)\n",
    "  \n",
    "    # Performing training\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3,random_state = 10)\n",
    "n_scores = cross_val_score(clf_gini, x_train, ytrain_trans, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report pipeline performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Classification\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kbins = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "ytrain_trans = kbins.fit_transform(y_train)\n",
    "ytest_trans = kbins.transform(y_test)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "model.fit(x_train, ytrain_trans)\n",
    "\n",
    "print(model.score(x_train, ytrain_trans)*100,'%')\n",
    "print(model.score(x_test, ytest_trans)*100,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
